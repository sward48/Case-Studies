---
title: "Hamden Appraised Value 'Fairness', Part 2: Data Acquisition"
format: html
---

# Introduction

The state of Connecticut compiles property data from municipalities across the state and provides it for viewing and downloading on the state government website's CT Geodata Portal https://geodata.ct.gov/pages/parcels. Data can also be obtained from the property value assessor's website. For example, here is the website for Hamden, CT: https://gis.vgsi.com/hamdenct/.

The file Connecticut_CAMA_and_Parcel_Layer_3895368049124948111 contains data obtained from CT. The property data contain information like location, mailing address, assessed property value, size of the plot of land in acres, floor space in sq ft, whether the property is commercial or residential, etc., and for homes it has details like number of bedrooms, number of bathrooms, etc., and the most recent sale price for each property, and the date of the sale. This is similar to the data you saw in S&DS 361/661, except we aren't providing shapefiles for the property boundaries.

The sales_data.xlsx file contains sales data for recent property sales. It is not known whether this data contains more, less, or the same sales information that is contained in the property data.

# Your goals

A Hamden resident who recently purchased his house had his assessed property value significantly increase within a year of the purchase. He began to question whether the assessed value was fair. He would like to use data to see if there is any evidence he could use to contest his assessed value.

Your goal is determine whether the assessed values for residential properties in Hamden, CT are fair and determine if there is any evidence to support contesting the assessed value. Write up your analysis and submit a short PDF report on explaining your reasoning.

Note that when an assessment company decides on a new set of assessed values for properties in a given year (typically using some sort of model), they do a sanity check and compare their assessed values to actual sale prices from the past year.

As some of you found, the state-wide data from 2024 is missing sale prices for Hamden for some reason. The state-wide data from 2023 that we used in class last spring does have sale prices for Hamden. I wrongly assumed the 2024 data would be fine since the 2023 data was fine. Rookie mistake!

We could potentially use the 2023 data to do the analysis, but maybe we'd want more recent data. We can obtain this data directly from the Vision's website https://gis.vgsi.com/hamdenct/. On that website there is one webpage for every property. For example, here is the first Hamden property from the first row of the state-wide dataset (after filtering for `Town.Name == 'Hamden'` with property ID (PID) equal to 1: <https://gis.vgsi.com/hamdenct/Parcel.aspx?Pid=1>. Among other things, the HTML pages contain information appraised value (most recent, and a short history), sale date and price for recent transactions, and information about the property that we have seen previous (bedrooms, square footage of living area, etc). This info is unfortunately not in one nice neat table, but the information can be extracted and put into a data frame.

[This .zip file](https://yaleedu-my.sharepoint.com/:u:/g/personal/brian_macdonald_yale_edu/ERDOKwhS_s1Bn2f3GFAg5gABBrtaf-g-bAsOetpW44j7yA?e=QHhBRf) contains one HTML file for almost all of the properties in Hamden, so you don't have to spend the time to scrape them all. Extract the information you need to assess the "fairness" of the appraised values that were determined by Vision. To extract that information, you can likely use some combination of regular expressions and functions that read HTML tables like those summarized here: <https://bmacgtpm.github.io/notes/parsing-html-tables.html>.

# Data sources

Folder rawdata: 
* `centroids.no.geometry.rds`: centroids of properties in CT (from Brian) 
* `Connecticut_CAMA_and_Parcel_Layer_3895368049124948111.csv`: property data for CT from the [link](https://yaleedu-my.sharepoint.com/:u:/g/personal/brian_macdonald_yale_edu/EVAE5NykXsdLlqI4ufT6nBwBA0_oJh1jqjPioEMQ_G7Fmg?e=qoYauD) provided by Brian: 

Folder data: - `sales_scraped.csv`: sales data scraped from the HTML files

Folder Hamden_Sept2025: - Downloaded from the provided zip file: [This .zip file](https://yaleedu-my.sharepoint.com/:u:/g/personal/brian_macdonald_yale_edu/ERDOKwhS_s1Bn2f3GFAg5gABBrtaf-g-bAsOetpW44j7yA?e=QHhBRf)

```{r}
# make a figures directory if it doesn't exist
if (!dir.exists("figures")){
    dir.create("figures")
}
```

```{r}
library(readxl)
library(dplyr)
library(janitor)
library(ggplot2)
library(stringr)
library(rvest)
```

# Preliminary analysis of the data

Load the data and plot distribution of assessed value / sale price

```{r}
hamden <- readRDS("data/hamden.RDS") %>% clean_names()
sales <- read.csv("data/sales_scraped.csv")
# geo <- readRDS("centroids.no.geometry.rds") %>% 
#     filter(Town_Name == "HAMDEN") %>%
#     mutate(pid = as.integer(gsub("35650-", "", Link))) %>%
#     filter(!is.na(pid)) %>%
#     select(pid, locatio=Location, lon = point.x, lat = point.y)

property_keep <- c(
  "pid", #"link", 
  "land_acres", "living_area", "effective_area", "total_rooms", "number_of_bedroom",
  "number_of_baths", "number_of_half_baths", "occupancy", "ayb", "eyb",
  "shape_area", "shape_length"
)
hamden <- hamden %>%
    mutate(pid = as.integer(gsub("35650-", "", link))) %>%
    filter(!is.na(pid)) %>%
    select(all_of(property_keep))

# merge on pid (keep all properties; bring in sales/appraisal cols)
merged <- hamden %>% 
    left_join(sales, by = "pid") # %>% left_join(geo, by = "pid") 


# sanity check: compare assessed value in the property dataset and the scraped sales dataset
# head(merged[, c("pre_yr_assessed_total", "assessed_total", "total_2024", "total_2023")],10)
```

Filter the data to sales in 2023 and 2024, and filtering outliers with assessment ratio \> 2

```{r}
# Remove rows with sale_price=0 
merged <- merged[merged["sale_price"] != 0, ]

sold_2023 <- merged %>% 
    filter(!is.na(sale_price), 
           !is.na(total_2023),
           !is.na(sale_date),
           as.numeric(format(as.Date(sale_date), "%Y")) == 2023) %>%
    mutate(ratio = total_2023 / sale_price) #%>%
    #filter(ratio < 2) # remove outliers with ratio > 2
sold_2024 <- merged %>% 
    filter(!is.na(sale_price), 
           !is.na(total_2024),
           !is.na(sale_date),
           as.numeric(format(as.Date(sale_date), "%Y")) == 2024) %>%
    mutate(ratio = total_2024 / sale_price) #%>%
    #filter(ratio < 2) # remove outliers with ratio > 2
```

Combine 2023 and 2024 data to plot histogram of the assessment ratio (for both years)

```{r}
sold_2023_2024 <- rbind(sold_2023, sold_2024)

# sales in 2023 and 2024
hist(sold_2023_2024$ratio, breaks = 50, xlim = c(0, 2),
     xlab = "Assessed Value / Sale Price", main="",
     border = "grey", )
abline(v = 0.7, col = "red", lty = 1)
abline(v = median(sold_2023_2024$ratio, na.rm = TRUE), col = "blue", lty = 2)
legend("topright", legend = c("0.7 line", "Median"), col = c("red", "blue"), lty = 1)
box(col = "black")

# save as pdf
dev.copy2pdf(file = "figures/ratio_2023_2024.pdf", width = 7, height = 5)
```

To compare the distributions of the assessment ratio for 2023 and 2024, the densities are compared below.

```{r}
# Density plots for 2023 and 2024 
plot(density(sold_2023$ratio, na.rm = TRUE), col = "blue", lwd = 2,
     xlim = c(0, 2), ylim = c(0, 6),
     xlab = "Assessed Value / Sale Price", ylab = "Density",
     main = "")
lines(density(sold_2024$ratio, na.rm = TRUE), col = "red", lwd = 2)
abline(v = 0.7, col = "black", lty = 2, lwd = 1.5)
abline(v = median(sold_2023$ratio, na.rm = TRUE), col = "blue", lty = 3, lwd = 1.5)
abline(v = median(sold_2024$ratio, na.rm = TRUE), col = "red", lty = 3, lwd = 1.5)
legend("topright", legend = c("2023", "2024", "0.7 line"), 
       col = c("blue", "red", "black"), lty = c(1, 1, 2), lwd = c(2, 2, 1.5))

# save as pdf
dev.copy2pdf(file = "figures/density_2023_2024.pdf", width = 7, height = 5)
```

And associated table with the figures above

```{r}
# Summary table with mean, median, sd of ratio for 2023 and 2024
year_table <- data.frame(Year = c(2023, 2024, "Overall"),
      Mean = c(mean(sold_2023$ratio, na.rm = TRUE), mean(sold_2024$ratio, na.rm = TRUE), mean(sold_2023_2024$ratio, na.rm = TRUE)),
      Median = c(median(sold_2023$ratio, na.rm = TRUE), median(sold_2024$ratio, na.rm = TRUE), median(sold_2023_2024$ratio, na.rm = TRUE)),
      SD = c(sd(sold_2023$ratio, na.rm = TRUE), sd(sold_2024$ratio, na.rm = TRUE), sd(sold_2023_2024$ratio, na.rm = TRUE))
)

# print table and round to 3 decimal places
year_table <- year_table %>%
    mutate(across(c(Mean, Median, SD), ~ round(., 3)))
year_table
```

# Feature analysis: bedrooms, living area, sale price

```{r}
# Two way table with number_of_bedroom and 2023 and 2024, median ratio
# for bedrooms 1:7
bedroom_table <- data.frame(
    Bedrooms = 1:7,
    Count_2023 = sapply(1:7, function(x) sum(sold_2023$number_of_bedroom == x, na.rm = TRUE)),
    Median_2023 = sapply(1:7, function(x) median(sold_2023$ratio[sold_2023$number_of_bedroom == x], na.rm = TRUE)),
    Count_2024 = sapply(1:7, function(x) sum(sold_2024$number_of_bedroom == x, na.rm = TRUE)),
    Median_2024 = sapply(1:7, function(x) median(sold_2024$ratio[sold_2024$number_of_bedroom == x], na.rm = TRUE))
)
bedroom_table <- bedroom_table %>%
    mutate(across(c(Median_2023, Median_2024), ~ round(., 3)))
bedroom_table

# remove bedroom count = 1
bedroom_table <- bedroom_table[bedroom_table$Bedrooms != 1, ]

sold_2023 <- sold_2023 %>% 
    # 1 beds set into 2 and above 6 merged into bedroom 6
    mutate(beds2_6 = case_when(
        number_of_bedroom <= 2 ~ 2,
        number_of_bedroom >= 6 ~ 6,
        TRUE ~ number_of_bedroom
    ))
sold_2024 <- sold_2024 %>%
    # 1 beds set into 2 and above 6 merged into bedroom 6
    mutate(beds2_6 = case_when(
        number_of_bedroom <= 2 ~ 2,
        number_of_bedroom >= 6 ~ 6,
        TRUE ~ number_of_bedroom
    ))

# boxplot with for 2023 and 2024 (just for 2-7 bedrooms)
boxplot(ratio ~ factor(beds2_6), 
        data = sold_2023,
        at = rep(1:5) + c(-0.15),
        col = c("lightblue"),
        xlab = "Number of Bedrooms", ylab = "Assessed / Sale Price",
        main = "",
        boxwex = 0.25, 
        ylim = c(0, 2),
        xaxt = "n") # remove xlabels
boxplot(ratio ~ factor(beds2_6), 
        data = sold_2024,
        at = rep(1:5) + c(+0.15),
        col = c("lightpink"),
        boxwex = 0.25,
        xaxt = "n", # remove xlabels
        add=TRUE) 
abline(h = 0.7, col = "grey4", lty = 2, lwd = 1)
axis(1, c(1:5), labels = c("<=2", 3, 4, 5, ">=6"))
text(0.5, 0.76, "0.7 Line", col = "black", cex = 0.8)
box()
legend("topright", legend = c("2023", "2024"), fill = c("lightblue", "lightpink"))

# save as pdf
dev.copy2pdf(file = "figures/boxplot_bedrooms.pdf", width = 7, height = 5)
```

```{r}
sold_2023_living <- sold_2023 %>% 
    filter(!is.na(living_area), living_area > 100)
sold_2024_living <- sold_2024 %>% 
    filter(!is.na(living_area), living_area > 100)

# Fir a log-log linear models
lm_living23 <- lm(log(ratio) ~ log(living_area), data = sold_2023_living)
lm_living24 <- lm(log(ratio) ~ log(living_area), data = sold_2024_living)

# Plot points and regression lines for 2023
plot(log(sold_2023_living$living_area), log(sold_2023_living$ratio), 
     xlab = "Living Area (log sq ft)", ylab = "Assessed / Sale Price (log)",
     pch = 19, col = alpha(rgb(0, 0, 1, 0.3),0.2), cex=0.6)
abline(lm_living23, col = "blue", lwd = 2)

# and 2024 on the same plot (transparent points)
points(log(sold_2024_living$living_area), log(sold_2024_living$ratio), 
       pch = 19, col = alpha(rgb(1, 0, 0, 0.3),0.2), cex=0.6)
abline(lm_living24, col = "red", lwd = 2)
legend("topright", legend = c("2023", "2024"), col = c("blue", "red"), lty = 1, lwd = 2)

# save as pdf
dev.copy2pdf(file = "figures/living_area_loglog.pdf", width = 7, height = 5)

```

```{r}
lm_sales23 <- lm(log(ratio) ~ log(sale_price), data = sold_2023)
lm_sales24 <- lm(log(ratio) ~ log(sale_price), data = sold_2024)

# Plot points and regression lines for 2023
plot(log(sold_2023$sale_price), log(sold_2023$ratio), 
     xlab = "Sale Price (log $)", ylab = "Assessed/Sale Price (log)",
     pch = 19, col = alpha(rgb(0, 0, 1, 0.3),0.2), cex=0.6)
abline(lm_sales23, col = "blue", lwd = 2)

# and 2024 on the same plot (transparent points)
points(log(sold_2024$sale_price), log(sold_2024$ratio), 
       pch = 19, col = alpha(rgb(1, 0, 0, 0.3),0.2), cex=0.6)
abline(lm_sales24, col = "red", lwd = 2)
legend("topright", legend = c("2023", "2024"), col = c("blue", "red"), lty = 1, lwd = 2)

# save as pdf
dev.copy2pdf(file = "figures/sale_price_loglog.pdf", width = 7, height = 5)
```

# Hypothesis tests

```{r}
# fit a t-test (the data is approximately normal for 2023 and 2024 but not for the combined data) for each year separately
t.test(sold_2023$ratio, mu = 0.70)
t.test(sold_2024$ratio, mu = 0.70)

# Wilcoxon signed rank test (non-parametric), for the combined data since the distribution is not normal
wilcox.test(sold_2023_2024$ratio - 0.70, conf.int = TRUE)
```

GLM and LM, engineering features - month by month, does the sale price vary through the year? predict the sale price form features - debias months or season - mds: multidimensional scaling - r package https://cran.r-project.org/web/packages/gpairs/index.html - distance between points, reconstruct a map that preserves distances - to recover the map of the properties - clustering algorithms and regression on the clusters (k-means etc)

spatial: - debias number of bedrooms or bathrooms? to get a cleaner look of location - continuous color bar - debias for bedrooms

weekenesses, from residuals etc, leads to more - rolling average more informative - rolling average for 2023 and 2024, simplest nl model - geom.smooth could be used, smooth rolling average